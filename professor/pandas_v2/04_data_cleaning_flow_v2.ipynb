{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.googleusercontent.com/assets/colab-badge.svg)](https://colab.research.google.com)\n",
        "\n",
        "Si tu repo está en GitHub, usa este enlace editando USER/REPO/BRANCH:\n",
        "[Open in Colab (GitHub)](https://colab.research.google.com/github/USER/REPO/blob/BRANCH/professor/pandas_v2/04_data_cleaning_flow_v2.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 v2 Limpieza de datos end-to-end (versión detallada)\n",
        "\n",
        "Objetivos:\n",
        "- Construir datos \"sucios\" realistas y planificar su limpieza.\n",
        "- Normalizar tipos (texto, numéricos, fechas), tratar nulos y duplicados.\n",
        "- Homologar categorías con catálogos (joins) y validar reglas.\n",
        "- Guardar un dataset limpio para análisis/EDA.\n",
        "\n",
        "Nota: Cada celda de código es corta y va precedida de una explicación.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparación e importaciones\n",
        "\n",
        "Usaremos `pandas` (`pd`), `numpy` (`np`) y `pathlib.Path` para rutas. En la celda de abajo:\n",
        "- `Path(...).mkdir(parents=True, exist_ok=True)` crea la carpeta de salida si no existe.\n",
        "- Mostramos versiones con `pd.__version__`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Versiones:\")\n",
        "print(\"pandas=\", pd.__version__)\n",
        "\n",
        "OUT_DIR = Path(\"professor/pandas_v2/data/clean\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Salida:\", OUT_DIR.as_posix())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creamos datos \"sucios\" (ventas y clientes)\n",
        "\n",
        "Usamos `pd.DataFrame({...})` para construir ejemplos con errores reales:\n",
        "- Fechas con formatos mixtos, montos como texto con símbolos y espacios.\n",
        "- Espacios y mayúsculas/minúsculas inconsistentes en texto.\n",
        "- Duplicados en `venta_id` y `cliente_id`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ventas_raw = pd.DataFrame({\n",
        "    \"venta_id\": [1, 2, 2, 3, 4, 5],\n",
        "    \"cliente_id\": [101, 102, 102, 103, None, 104],\n",
        "    \"fecha\": [\n",
        "        \"2024-01-01\", \"2024/01/02\", \"02-01-2024\", \"2024-13-01\", None, \"2024-01-05 10:00\"\n",
        "    ],\n",
        "    \"monto\": [\"$100\", \"200.5 \", \"dos\", None, \"-5\", \" 300\"],\n",
        "    \"categoria\": [\" A \", \"b\", \"B\", None, \"A\", \"b\"],\n",
        "    \"canal\": [\"Web\", \" tienda \", \"Tienda\", \"WEB\", \"?\", \"web\"],\n",
        "})\n",
        "\n",
        "clientes_raw = pd.DataFrame({\n",
        "    \"cliente_id\": [101, 102, 102, 105],\n",
        "    \"nombre\": [\" Ana \", \"luis\", \"LUIS\", \"Mara\"],\n",
        "    \"pais\": [\" mx \", \"MX\", \"mx\", \"US\"],\n",
        "})\n",
        "\n",
        "print(\"Ventas sucias:\")\n",
        "print(ventas_raw)\n",
        "print(\"\\nClientes sucios:\")\n",
        "print(clientes_raw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vistazo rápido (head, info)\n",
        "\n",
        "Usamos `DataFrame.head()` para una muestra rápida y `DataFrame.info()` para ver tipos y nulos por columna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ventas_raw.head():\")\n",
        "print(ventas_raw.head())\n",
        "print(\"\\nclientes_raw.head():\")\n",
        "print(clientes_raw.head())\n",
        "print(\"\\nInfo ventas_raw:\")\n",
        "print(ventas_raw.info())\n",
        "print(\"\\nInfo clientes_raw:\")\n",
        "print(clientes_raw.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalización de texto\n",
        "\n",
        "Funciones usadas en la celda siguiente:\n",
        "- `Series.astype(str)` para garantizar tipo string.\n",
        "- `Series.str.strip()` para quitar espacios al inicio/fin.\n",
        "- `Series.str.title()`, `Series.str.upper()`, `Series.str.lower()` para homogenizar casing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ventas = ventas_raw.copy()\n",
        "clientes = clientes_raw.copy()\n",
        "\n",
        "clientes[\"nombre\"] = clientes[\"nombre\"].astype(str).str.strip().str.title()\n",
        "clientes[\"pais\"] = clientes[\"pais\"].astype(str).str.strip().str.upper()\n",
        "\n",
        "ventas[\"categoria\"] = ventas[\"categoria\"].astype(str).str.strip().str.lower()\n",
        "ventas[\"canal\"] = ventas[\"canal\"].astype(str).str.strip().str.lower()\n",
        "\n",
        "print(\"Texto normalizado (clientes):\\n\", clientes.head(), sep=\"\")\n",
        "print(\"\\nTexto normalizado (ventas):\\n\", ventas.head(), sep=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversión de tipos (numérico y fecha)\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `Series.str.replace()` para remover símbolos y espacios.\n",
        "- `pd.to_numeric(..., errors='coerce')` para convertir `monto` a número.\n",
        "- `pd.to_datetime(..., errors='coerce', utc=True)` para parsear y normalizar `fecha` a UTC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ventas[\"monto\"] = ventas[\"monto\"].astype(str).str.replace(\"$\", \"\", regex=False).str.strip()\n",
        "ventas[\"monto\"] = pd.to_numeric(ventas[\"monto\"], errors=\"coerce\")\n",
        "ventas[\"fecha\"] = pd.to_datetime(ventas[\"fecha\"], errors=\"coerce\", utc=True)\n",
        "\n",
        "print(\"Montos y fechas convertidos:\")\n",
        "print(ventas[[\"monto\", \"fecha\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nulos: diagnóstico y tratamiento\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `DataFrame.isna().sum()` para conteo de nulos.\n",
        "- Asignación condicional con `DataFrame.loc[cond, col] = ...`.\n",
        "- `Series.replace({...})` para marcar valores especiales como `NaN`.\n",
        "- `Series.fillna(...)` para imputar valores faltantes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Conteo de nulos antes:\")\n",
        "print(ventas.isna().sum())\n",
        "\n",
        "ventas.loc[ventas[\"monto\"] < 0, \"monto\"] = np.nan\n",
        "ventas[\"canal\"] = ventas[\"canal\"].replace({\"?\": np.nan})\n",
        "\n",
        "print(\"\\nImputamos 'canal' faltante con 'web' (ejemplo simple):\")\n",
        "ventas[\"canal\"] = ventas[\"canal\"].fillna(\"web\")\n",
        "\n",
        "print(\"\\nConteo de nulos después:\")\n",
        "print(ventas.isna().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reemplazos y estandarización\n",
        "\n",
        "Usamos `Series.replace({...})` para mapear valores a categorías estándar y para tratar variantes (`\"a\"→\"A\"`, `\"b\"→\"B\"`). Si hubiera patrones, puede usarse `regex=True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ventas[\"categoria\"] = ventas[\"categoria\"].replace({np.nan: \"desconocido\"})\n",
        "ventas[\"categoria\"] = ventas[\"categoria\"].replace({\"a\": \"A\", \"b\": \"B\", \"none\": \"desconocido\"})\n",
        "\n",
        "print(ventas[[\"categoria\", \"canal\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Catálogo y homologación por join\n",
        "\n",
        "En la celda de abajo:\n",
        "- Construimos `cat_map` con `pd.DataFrame`.\n",
        "- Homologamos con `pd.merge(..., how='left', indicator=True)` para ver `_merge` (`left_only/right_only/both`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_map = pd.DataFrame({\n",
        "    \"categoria\": [\"A\", \"B\", \"desconocido\"],\n",
        "    \"categoria_final\": [\"A\", \"B\", \"DESCONOCIDO\"],\n",
        "})\n",
        "\n",
        "merged_cats = pd.merge(\n",
        "    ventas[[\"venta_id\", \"categoria\"]],\n",
        "    cat_map,\n",
        "    on=\"categoria\",\n",
        "    how=\"left\",\n",
        "    indicator=True,\n",
        ")\n",
        "print(\"Resultado de join de categorías (primeras filas):\")\n",
        "print(merged_cats.head())\n",
        "print(\"\\nConteo por _merge:\")\n",
        "print(merged_cats[\"_merge\"].value_counts())\n",
        "\n",
        "ventas = ventas.merge(cat_map, on=\"categoria\", how=\"left\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enriquecimiento con clientes (left join) y auditoría\n",
        "\n",
        "Usamos `pd.merge(ventas, clientes, on='cliente_id', how='left', indicator=True)` para enriquecer y auditar con `_merge` cuántas filas no hicieron match (`left_only`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ventas_enr = pd.merge(\n",
        "    ventas,\n",
        "    clientes,\n",
        "    on=\"cliente_id\",\n",
        "    how=\"left\",\n",
        "    indicator=True,\n",
        ")\n",
        "print(\"Resultado de enriquecimiento (primeras filas):\")\n",
        "print(ventas_enr.head())\n",
        "print(\"\\nConteo por _merge (espera left_only si cliente_id faltó o no existía en clientes):\")\n",
        "print(ventas_enr[\"_merge\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Duplicados y llaves\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `Series.duplicated()` para detectar duplicados.\n",
        "- `DataFrame.drop_duplicates(subset=[...], keep='first')` para deduplicar por llave.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Duplicados en ventas por venta_id:\")\n",
        "print(ventas_enr[\"venta_id\"].duplicated().value_counts())\n",
        "\n",
        "ventas_enr = ventas_enr.drop_duplicates(subset=[\"venta_id\"], keep=\"first\")\n",
        "print(\"\\nVentas tras drop_duplicates:\")\n",
        "print(len(ventas_enr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validaciones y reglas de negocio\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `Series.clip(lower=0)` para cortar valores negativos.\n",
        "- `DataFrame.dropna(subset=[...])` para exigir presencia de campos críticos (p. ej., `fecha`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ventas_enr[\"monto\"] = ventas_enr[\"monto\"].clip(lower=0)\n",
        "registros_con_fecha = ventas_enr[\"fecha\"].notna().sum()\n",
        "print(\"Registros con fecha válida:\", registros_con_fecha)\n",
        "\n",
        "# Si consideras obligatorio 'fecha' para toda venta, filtra:\n",
        "ventas_validas = ventas_enr.dropna(subset=[\"fecha\"])  # decisión explícita\n",
        "print(\"Ventas válidas (sin NaT en fecha):\", len(ventas_validas))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outliers (percentiles y `clip`)\n",
        "\n",
        "Herramientas sugeridas para la celda siguiente (si decides aplicarlo):\n",
        "- `Series.quantile([0.01, 0.99])` para estimar umbrales p1–p99.\n",
        "- `Series.clip(lower=..., upper=...)` para recortar extremos de `monto`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deduplicación de clientes y `validate`\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `DataFrame.drop_duplicates(subset=[...])` para deduplicar catálogo de clientes.\n",
        "- `pd.merge(..., validate='m:1')` para asegurar relación muchas-ventas-a-un-cliente sin duplicaciones inesperadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clientes_dedup = clientes.drop_duplicates(subset=[\"cliente_id\"], keep=\"first\")\n",
        "print(\"Clientes antes/after dedup:\")\n",
        "print(len(clientes), len(clientes_dedup))\n",
        "\n",
        "ventas_enr_v = pd.merge(\n",
        "    ventas,\n",
        "    clientes_dedup,\n",
        "    on=\"cliente_id\",\n",
        "    how=\"left\",\n",
        "    validate=\"m:1\",\n",
        "    indicator=True,\n",
        ")\n",
        "print(\"\\nEnriquecimiento validado m:1 (primeras filas):\")\n",
        "print(ventas_enr_v.head())\n",
        "print(\"\\n_merge counts:\")\n",
        "print(ventas_enr_v[\"_merge\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen de calidad y validaciones rápidas\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `Series.is_unique` para validar unicidad de `venta_id`.\n",
        "- `DataFrame.isna().sum()` para conteo de nulos en campos clave.\n",
        "- `Series.value_counts(dropna=False)` para distribuciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Unicidad de venta_id (espera True):\", ventas_enr_v[\"venta_id\"].is_unique)\n",
        "print(\"\\nNulos en campos clave:\")\n",
        "print(ventas_enr_v[[\"venta_id\", \"cliente_id\", \"fecha\", \"monto\"]].isna().sum())\n",
        "\n",
        "print(\"\\nDistribución de canal:\")\n",
        "print(ventas_enr_v[\"canal\"].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\nDistribución de categoria_final:\")\n",
        "print(ventas_enr_v[\"categoria_final\"].value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guardado de datos limpios\n",
        "\n",
        "Funciones usadas abajo:\n",
        "- `DataFrame.sort_values(...)` para ordenar al exportar.\n",
        "- `DataFrame.to_csv(...)` y `DataFrame.to_parquet(...)` para persistencia eficiente.\n",
        "- `Path` para construir rutas de salida.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_finales = [\n",
        "    \"venta_id\", \"cliente_id\", \"fecha\", \"monto\",\n",
        "    \"categoria_final\", \"canal\", \"nombre\", \"pais\"\n",
        "]\n",
        "limpio_v2 = ventas_enr_v[cols_finales].sort_values([\"cliente_id\", \"fecha\", \"venta_id\"], na_position=\"last\")\n",
        "\n",
        "csv_path = OUT_DIR / \"dataset_limpio_v2.csv\"\n",
        "parquet_path = OUT_DIR / \"dataset_limpio_v2.parquet\"\n",
        "\n",
        "limpio_v2.to_csv(csv_path, index=False)\n",
        "try:\n",
        "    limpio_v2.to_parquet(parquet_path, index=False)\n",
        "    print(\"Guardado CSV y Parquet:\", csv_path.as_posix(), parquet_path.as_posix())\n",
        "except Exception as e:\n",
        "    print(\"Guardado CSV, Parquet no disponible:\", csv_path.as_posix(), \"|\", e)\n",
        "\n",
        "print(\"\\nMuestra final:\")\n",
        "print(limpio_v2.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checklist final\n",
        "\n",
        "- Tipos normalizados (`monto` numérico, `fecha` UTC, textos homogéneos).\n",
        "- Nulos tratados: canales imputados, montos negativos a `NaN`.\n",
        "- Catálogo aplicado a `categoria` → `categoria_final`.\n",
        "- Enriquecimiento con `clientes` validado `m:1`.\n",
        "- Duplicados removidos en `venta_id` y catálogo deduplicado.\n",
        "- Datos guardados en `professor/pandas_v2/data/clean/` como `dataset_limpio_v2.*`.\n",
        "\n",
        "Siguiente: usa el notebook 05 para EDA con `groupby`, `pivot_table` y `MultiIndex`.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
